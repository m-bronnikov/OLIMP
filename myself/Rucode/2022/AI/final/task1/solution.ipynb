{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<center><h1> Rucode 6.0 Car Color Detection</h1></center>"
      ],
      "metadata": {
        "id": "9hbO9FHtgBrJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To reproduce result sucessfully is needed:\n",
        "- Download provided by organizators zip archive with train data and rename it to `dataset.zip`\n",
        "- Launch this notebook."
      ],
      "metadata": {
        "id": "XRWkHQnMgSqg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Required imports"
      ],
      "metadata": {
        "id": "fHT83174Sq4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import matplotlib.image as img\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, losses, utils"
      ],
      "metadata": {
        "id": "SAvLuxuO2XJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unzip dataset archive"
      ],
      "metadata": {
        "id": "_p0X7ahYS099"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! rm -r sample_data &> /dev/null\n",
        "! rm -r public_test sample_submission.csv train &> /dev/null\n",
        "! unzip dataset.zip &> /dev/null\n",
        "! ls train"
      ],
      "metadata": {
        "id": "wOgjMipz1ENH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset separated to train data and test data needed to evaluate"
      ],
      "metadata": {
        "id": "eTZ2I2bTS2SM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = 'train'\n",
        "test_dir = 'public_test'"
      ],
      "metadata": {
        "id": "Z0foLtPu1CtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take a look at some images and their props."
      ],
      "metadata": {
        "id": "GGpKHzOV8pYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Some shapes:\", img.imread(\"train/Yellow/3567.jpg\").shape, img.imread(\"train/Red/3011.jpg\").shape)\n",
        "print(\"Max value of some image:\", img.imread(\"train/Yellow/3567.jpg\").max())\n",
        "print(\"dtype:\", img.imread(\"train/Yellow/3567.jpg\").dtype)\n",
        "\n",
        "print(\"Some image:\")\n",
        "# plt.imshow(img.imread(\"train/Yellow/3567.jpg\"));\n",
        "# plt.imshow(img.imread(\"train/Yellow/3751.jpg\"));\n",
        "# plt.imshow(img.imread(\"train/Yellow/3633.jpg\"));\n",
        "plt.imshow(img.imread(\"train/Yellow/3498.jpg\"));\n",
        "# plt.imshow(img.imread(\"train/Red/3011.jpg\"));\n",
        "# plt.imshow(img.imread(\"train/Grey/1533.jpg\"));"
      ],
      "metadata": {
        "id": "21Me4hPz8oaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As far as we see shapes are different and we need to tramsform images to equal shapes.\n",
        "\n",
        "We can use low-resolution shape because it's not required to work with hi-res to determinate color. Let it be equal to $(32, 32)$."
      ],
      "metadata": {
        "id": "gC4ReSVk9XEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "overall_shape = (32, 32)"
      ],
      "metadata": {
        "id": "mfIbILYcDNcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's import train dataset to in-memory representaion."
      ],
      "metadata": {
        "id": "7BdmgdIp-Fb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = []\n",
        "\n",
        "train_imgs = []\n",
        "train_lbls = []\n",
        "\n",
        "# iterate over all labels in train dataset\n",
        "for i, label in enumerate(os.listdir(train_dir)):\n",
        "  labels.append(label)\n",
        "  dir = os.path.join(train_dir, label)\n",
        "\n",
        "  # iterate over all images of label\n",
        "  for filename in os.listdir(dir):\n",
        "    filepath = os.path.join(dir, filename)\n",
        "    image = Image.open(filepath)\n",
        "    image = np.array(image.resize(overall_shape))\n",
        "    train_imgs.append(image)\n",
        "    train_lbls.append(i)\n",
        "    \n",
        "train_imgs = np.stack(train_imgs)\n",
        "train_lbls = np.stack(train_lbls)\n",
        "\n",
        "train_imgs.shape, train_lbls.shape"
      ],
      "metadata": {
        "id": "JRszKyxhy8FB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's import test dataset to in-memory representaion."
      ],
      "metadata": {
        "id": "nG06dSUOQ-zT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_imgs = []\n",
        "sorted_files = sorted(os.listdir(test_dir), key=lambda x: int(x.split('.')[0]))\n",
        "\n",
        "# iterate over sorted by name images of dataset\n",
        "for filename in sorted_files:\n",
        "  filepath = os.path.join(test_dir, filename)\n",
        "  image = Image.open(filepath)\n",
        "  image = np.array(image.resize(overall_shape))\n",
        "  test_imgs.append(image)\n",
        "\n",
        "test_imgs = np.stack(test_imgs)\n",
        "\n",
        "test_imgs.shape"
      ],
      "metadata": {
        "id": "lUsuV6v5ztgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply data transforamtions to them:\n",
        "\n",
        "* Normalise train data (min-max normalistion is common choise for imges)\n",
        "* Make labels as categorical (with one-hot encoding) "
      ],
      "metadata": {
        "id": "2ioK59wkcPhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize images\n",
        "train_imgs = train_imgs / 255.0\n",
        "test_imgs = test_imgs / 255.0\n",
        "print(\"min:\", train_imgs.min(), \"max:\", train_imgs.max())\n",
        "\n",
        "# encode labels\n",
        "train_lbls = utils.to_categorical(train_lbls, len(labels))\n",
        "train_lbls.shape"
      ],
      "metadata": {
        "id": "iELxKX87cOn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split training dataset on training data and validation data in proportion $8 : 2$"
      ],
      "metadata": {
        "id": "z3nDls1fWrV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data_rate = 0.8\n",
        "training_data_size = int(training_data_rate * len(train_imgs))\n",
        "\n",
        "permut = np.random.RandomState(seed=42).permutation(len(train_imgs))\n",
        "\n",
        "valid_imgs = train_imgs[permut[training_data_size:]]\n",
        "valid_lbls = train_lbls[permut[training_data_size:]]\n",
        "\n",
        "train_imgs = train_imgs[permut[:training_data_size]]\n",
        "train_lbls = train_lbls[permut[:training_data_size]]\n",
        "\n",
        "len(train_imgs), len(valid_imgs)"
      ],
      "metadata": {
        "id": "SlytcJlLWokb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create some simple convolutional network for classification"
      ],
      "metadata": {
        "id": "OQbqxJFKTL3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "# module of convolutional layers\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=train_imgs.shape[1:]))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "# classification module with softmax at the end\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(len(labels), activation='softmax'))\n",
        "\n",
        "# summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "LtlKVuT_TLFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile model and choose hyperparameters"
      ],
      "metadata": {
        "id": "vYW2oA-aWDpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "epoches = 15 # to change"
      ],
      "metadata": {
        "id": "JC29RZUTWCW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model"
      ],
      "metadata": {
        "id": "iLQG7xbcawzJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_imgs, train_lbls, epochs=epoches, validation_data=(valid_imgs, valid_lbls))"
      ],
      "metadata": {
        "id": "R0RXt7iuavdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training process visualisation"
      ],
      "metadata": {
        "id": "evZllgDCeY0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14,8))\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "model.evaluate(valid_imgs,  valid_lbls, verbose=2)\n",
        "None"
      ],
      "metadata": {
        "id": "qX9LcAIJeXNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make prediction"
      ],
      "metadata": {
        "id": "gwYS6hWuhyFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_logits = model.predict(test_imgs)\n",
        "test_lbls = np.argmax(test_logits, axis=1)\n",
        "test_ans = np.array(labels)[test_lbls]\n",
        "test_ans[:5]"
      ],
      "metadata": {
        "id": "jOTR_2hFfQ5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check answer format"
      ],
      "metadata": {
        "id": "xk0TM8JQjDPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample = pd.read_csv('sample_submission.csv', index_col=False)\n",
        "sample.head()"
      ],
      "metadata": {
        "id": "4Iv3o9ijh2cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Serialize answer"
      ],
      "metadata": {
        "id": "ltsxbEkwh2_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ans_df = pd.DataFrame(test_ans)\n",
        "ans_df.to_csv('submit.csv', index=False, header=False)\n",
        "ans_df.head()"
      ],
      "metadata": {
        "id": "fBb5AXp2jL50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------\n",
        "\n",
        "**Made by Bronnikov Maksim**"
      ],
      "metadata": {
        "id": "isZn7Z9EjMg_"
      }
    }
  ]
}